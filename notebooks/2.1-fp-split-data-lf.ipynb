{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This notebook was used to do the training and testing split of the dataset for the Late Fusion model. The starting input is represented by the ASM points previously obtain with the R script that leverages the BlockCV package.\n",
        "\n",
        "Note that this notebook was ran in Colab, as the dataset was originally stored in Google Drive, so it might be necessary to install some packages in the environment to be executable locally (as well as changing the directories). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FM8QFuhwSgA_"
      },
      "outputs": [],
      "source": [
        "import geopandas as gpd\n",
        "import rasterio\n",
        "import shapely.geometry\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import shutil\n",
        "\n",
        "from shapely.geometry import box\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E5RET-T5SNAJ"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EvqVIwVQSW73"
      },
      "outputs": [],
      "source": [
        "split_number = '9'\n",
        "train_points = gpd.read_file(f'/content/drive/MyDrive/mgi_thesis/asm_points_split/split_{split_number}/train_data_split_{split_number}.geojson')\n",
        "test_points = gpd.read_file(f'/content/drive/MyDrive/mgi_thesis/asm_points_split/split_{split_number}/test_data_split_{split_number}.geojson')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BSBQn7blFL6a"
      },
      "outputs": [],
      "source": [
        "gt_dir = '/content/drive/MyDrive/mgi_thesis/gt_binary'\n",
        "planet_dir = '/content/drive/MyDrive/mgi_thesis/planet_images'\n",
        "s1_dir = '/content/drive/MyDrive/mgi_thesis/s1_images_both_orbits'\n",
        "\n",
        "base_dir = f'/content/drive/MyDrive/mgi_thesis/asm_dataset_split_{split_number}/fusion'\n",
        "train_dir = os.path.join(base_dir, 'training_data')\n",
        "test_dir = os.path.join(base_dir, 'testing_data')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ea8WJdr_D92M"
      },
      "outputs": [],
      "source": [
        "def get_image_boundaries(image_path):\n",
        "    \"\"\"\n",
        "    Extracts the boundaries of a raster image as a polygon. This function\n",
        "    will allow to determine which ASM sites fall within the area covered by\n",
        "    each satellite image.\n",
        "\n",
        "    Parameters:\n",
        "    image_path (str): Path to the raster image file.\n",
        "\n",
        "    Returns:\n",
        "    shapely.geometry.Polygon: A polygon of the image's geographical bounds.\n",
        "    \"\"\"\n",
        "    with rasterio.open(image_path) as dataset:\n",
        "        bounds = dataset.bounds\n",
        "        return box(bounds.left, bounds.bottom, bounds.right, bounds.top)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VUoiMTv8FscN"
      },
      "outputs": [],
      "source": [
        "image_boundaries = []\n",
        "image_types = ['Sentinel-1', 'Planet']\n",
        "directories = [s1_dir, planet_dir]\n",
        "\n",
        "for image_type, directory in zip(image_types, directories):\n",
        "    print(f\"Checking directory: {directory} for {image_type}\")\n",
        "    for image_filename in os.listdir(directory):\n",
        "        if image_filename.endswith('.tif') and not image_filename.startswith('gt_'):\n",
        "            image_path = os.path.join(directory, image_filename)\n",
        "            boundary = get_image_boundaries(image_path)\n",
        "\n",
        "            image_id_with_type = f\"{image_filename.replace('.tif', '')}\"\n",
        "            image_boundaries.append({'image_id': image_id_with_type, 'type': image_type, 'geometry': boundary})\n",
        "\n",
        "images_gdf = gpd.GeoDataFrame(image_boundaries, geometry='geometry')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tIcBCGXNFwq1"
      },
      "outputs": [],
      "source": [
        "# set the CRS again\n",
        "images_gdf = images_gdf.set_crs(4326)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aG-S_3NeE_n2"
      },
      "outputs": [],
      "source": [
        "def categorize_images(images_gdf, train_points_gdf, test_points_gdf):\n",
        "    \"\"\"\n",
        "    Perform spatial join and categorize images\n",
        "    \"\"\"\n",
        "    # spatial join points with images\n",
        "    train_overlap = gpd.sjoin(images_gdf, train_points_gdf, how='left', op='intersects')\n",
        "    test_overlap = gpd.sjoin(images_gdf, test_points_gdf, how='left', op='intersects')\n",
        "\n",
        "    # count points in each image\n",
        "    train_counts = train_overlap.groupby('image_id').size()\n",
        "    test_counts = test_overlap.groupby('image_id').size()\n",
        "\n",
        "    # determine category based on counts\n",
        "    image_category = {}\n",
        "    for image_id in images_gdf['image_id']:\n",
        "        train_count = train_counts.get(image_id, 0)\n",
        "        test_count = test_counts.get(image_id, 0)\n",
        "        category = 'training' if train_count > test_count else 'testing'\n",
        "        image_category[image_id] = category\n",
        "\n",
        "    return image_category\n",
        "\n",
        "# categorize images\n",
        "image_category = categorize_images(images_gdf, train_points, test_points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yhesTnz8kSRg"
      },
      "outputs": [],
      "source": [
        "def validate_and_copy(src_path, dest_path, file_type):\n",
        "    if os.path.exists(src_path):\n",
        "        shutil.copy(src_path, dest_path)\n",
        "        print(f\"Copying from {src_path} to {dest_path} for {file_type}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dw-eJls7FF33"
      },
      "outputs": [],
      "source": [
        "for image_id, category in image_category.items():\n",
        "    print(f\"Processing image ID: {image_id}, Category: {category}\")\n",
        "\n",
        "    if 's1' in image_id:\n",
        "        # handling for S1 images\n",
        "        print(image_id)\n",
        "        src_image_filename = image_id + '.tif'\n",
        "        src_gt_filename = 'nicfi_gt_' + image_id.split('s1_')[1] + '.tif'\n",
        "    elif 'nicfi' in image_id:\n",
        "        # handling for Planet images\n",
        "        src_image_filename = image_id + '.tif'\n",
        "        src_gt_filename = 'nicfi_gt_' + image_id.split('nicfi_')[1] + '.tif'\n",
        "    else:\n",
        "        # log an error if the image_id does not contain 's1' or 'nicfi'\n",
        "        print(f\"Unknown image type for image ID: {image_id}\")\n",
        "        continue\n",
        "\n",
        "    # source paths\n",
        "    src_image_path = os.path.join(s1_dir if 's1' in image_id else planet_dir, src_image_filename)\n",
        "    src_gt_path = os.path.join(gt_dir, src_gt_filename)\n",
        "\n",
        "    # target directories\n",
        "    dest_image_dir = os.path.join(base_dir, f\"{category}_data/\", 's1' if 's1' in image_id else 'planet')\n",
        "    dest_gt_dir = os.path.join(base_dir, f\"{category}_data/gt\")\n",
        "\n",
        "    # ensure destination directories exist\n",
        "    os.makedirs(dest_image_dir, exist_ok=True)\n",
        "    os.makedirs(dest_gt_dir, exist_ok=True)\n",
        "\n",
        "    # target paths\n",
        "    dest_image_path = os.path.join(dest_image_dir, src_image_filename)\n",
        "    dest_gt_path = os.path.join(dest_gt_dir, src_gt_filename)\n",
        "\n",
        "    # Log paths for verification\n",
        "    print(f\"Source image path: {src_image_path}\")\n",
        "    print(f\"Destination image path: {dest_image_path}\")\n",
        "    print(f\"Source GT path: {src_gt_path}\")\n",
        "    print(f\"Destination GT path: {dest_gt_path}\")\n",
        "\n",
        "    # copy files\n",
        "    validate_and_copy(src_image_path, dest_image_path, \"Image\")\n",
        "    validate_and_copy(src_gt_path, dest_gt_path, \"Ground Truth\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
